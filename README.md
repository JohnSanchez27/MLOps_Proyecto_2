# ğŸ“Œ Proyecto 2 - Nivel 2: OrquestaciÃ³n, mÃ©tricas y modelos

Este proyecto proporciona una arquitectura basada en Docker para la orquestaciÃ³n de flujos de trabajo en ciencia de datos utilizando Apache Airflow, MLflow y MinIO. La configuraciÃ³n incluye varios servicios para la gestiÃ³n de datos, modelos de machine learning y visualizaciÃ³n de resultados.

---

## ğŸ–¥ TecnologÃ­as Utilizadas

  1. Apache Airflow: Para la orquestaciÃ³n de flujos de trabajo.
  2. MLflow: Para la gestiÃ³n y seguimiento de experimentos de machine learning.
  3. MinIO: Para el almacenamiento de artefactos y modelos.
  4. PostgreSQL: Base de datos para Airflow.
  5. MySQL: Base de datos para MLflow.
  6. Redis: Cola de mensajes para Celery en Airflow.
  7. Streamlit: Interfaz web para la visualizaciÃ³n de resultados.
  8. FastAPI: Servicio de inferencia para modelos desplegados.

---

## ğŸ“Œ DescripciÃ³n

**Este proyecto implementa una arquitectura basada en Docker para la orquestaciÃ³n de flujos de trabajo en ciencia de datos, combinando Apache Airflow para la automatizaciÃ³n de procesos, MLflow para la gestiÃ³n de experimentos de machine learning y MinIO como almacenamiento distribuido de artefactos. AdemÃ¡s, incorpora PostgreSQL y MySQL para la gestiÃ³n de bases de datos, Redis para la mensajerÃ­a en Celery, FastAPI para la inferencia de modelos y Streamlit para la visualizaciÃ³n de resultados. La infraestructura permite ejecutar y monitorear experimentos, almacenar modelos y desplegar servicios de inferencia de manera escalable y reproducible.

## ğŸ“‚ Estructura del Proyecto

La estructura del proyecto estÃ¡ organizada para garantizar una correcta separaciÃ³n de responsabilidades y modularidad. Los flujos de trabajo se encuentran en la carpeta `dags/`, donde cada script maneja tareas especÃ­ficas como la carga, eliminaciÃ³n y entrenamiento de datos. La carpeta `datos/` contiene los archivos de entrada requeridos para el procesamiento, mientras que `logs/` almacena los registros de ejecuciÃ³n para facilitar el monitoreo. Los archivos de configuraciÃ³n, como `docker-compose.yml` y `Dockerfile`, permiten la implementaciÃ³n del entorno en contenedores, asegurando escalabilidad y reproducibilidad.

```
Proyecto_2/
â”‚â”€â”€ dags/                      # DefiniciÃ³n de flujos de trabajo
â”‚   â”œâ”€â”€ carga_dato.py          # Carga de datos
â”‚   â”œâ”€â”€ model_train.py         # Entrenamiento del modelo
â”‚â”€â”€ datos/                     # Almacenamiento de datos
â”‚â”€â”€ inference/                 # Inferencia del modelo
â”‚   â”œâ”€â”€ Dockerfile.app         # Dockerfile para la inferencia
â”‚   â”œâ”€â”€ main.py                # Script principal de inferencia
â”‚   â”œâ”€â”€ requirements_app.txt   # Dependencias para inferencia
â”‚â”€â”€ logs/                      # Registro de ejecuciÃ³n
â”‚   â”œâ”€â”€ README                 # InformaciÃ³n sobre logs
â”‚â”€â”€ minio/                     # ConfiguraciÃ³n para almacenamiento en MinIO
â”‚â”€â”€ mlflow/                    # ConfiguraciÃ³n de MLflow
â”‚   â”œâ”€â”€ Dockerfile.mlflow       # Dockerfile para MLflow
â”‚   â”œâ”€â”€ requirements_mlflow.txt # Dependencias para MLflow
â”‚â”€â”€ mysql/                     # Base de datos MySQL
â”‚â”€â”€ plugins/                   # Extensiones para Airflow
â”‚   â”œâ”€â”€ README                  # InformaciÃ³n sobre plugins
â”‚â”€â”€ streamlit/                 # Interfaz de usuario con Streamlit
â”‚   â”œâ”€â”€ api_streamlit.py        # API de Streamlit
â”‚   â”œâ”€â”€ Dockerfile.streamlit    # Dockerfile para Streamlit
â”‚   â”œâ”€â”€ requirements_streamlit.txt # Dependencias para Streamlit
â”‚â”€â”€ docker-compose.yml         # OrquestaciÃ³n de servicios
â”‚â”€â”€ Dockerfile                 # ConstrucciÃ³n de la imagen Docker
â”‚â”€â”€ README.md                  # DocumentaciÃ³n del proyecto
â”‚â”€â”€ requirements.txt           # Dependencias generales del proyecto

```
---
## ğŸ›  Servicios Definidos

  1. **Airflow**
  2. **MLflow**: mlflow_serv: Servidor de MLflow para el seguimiento de experimentos y mysql: Base de datos de MLflow.
  3. **Minio**: para Almacenamiento de objetos para artefactos de MLflow.
  4. **Servicios de Inferencia y VisualizaciÃ³n**: se utiliza inference como Servicio de inferencia basado en FastAPI y streamlit como AplicaciÃ³n web en Streamlit para la visualizaciÃ³n de resultados.
---
## âš™ï¸ ConfiguraciÃ³n y Variables de Entorno

---
* MLFLOW_S3_ENDPOINT_URL: URL del servidor MinIO.
* AWS_ACCESS_KEY_ID: Clave de acceso a MinIO.
* AWS_SECRET_ACCESS_KEY: Clave secreta de acceso a MinIO.
* AIRFLOW__CORE__EXECUTOR: CeleryExecutor para procesamiento distribuido.
* AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ConexiÃ³n a la base de datos de Airflow.
* AIRFLOW__CELERY__BROKER_URL: URL de Redis para Celery.
---

## ğŸš€ Pasos para Levantar el Contenedor

Para ejecutar este repositorio correctamente, es necesario contar con herramientas y configuraciones especÃ­ficas. `Docker` y `Docker Compose` permiten la ejecuciÃ³n de los servicios en contenedores, asegurando un entorno reproducible y estable. `Python 3.x` es el lenguaje base para los scripts de procesamiento de datos. AdemÃ¡s, las librerÃ­as listadas en `requirements.txt`, como `pandas`, `scikit-learn` e `imbalanced-learn`, proporcionan las funcionalidades necesarias para el anÃ¡lisis de datos y entrenamiento de modelos. Finalmente, `Apache Airflow` gestiona la ejecuciÃ³n de tareas automatizadas mediante flujos de trabajo definidos en `DAGs`. Adicionalmente, se recomienda contar con `PostgreSQL` y `MySQL` correctamente configurados para el almacenamiento de metadatos y la gestiÃ³n de experimentos en MLflow.

1. **Clonar el repositorio** o descargarlo en tu mÃ¡quina local.
   ```bash
   git clone https://github.com/JohnSanchez27/MLOps_Proyecto_2 #HTTPS
   git clone git@github.com:JohnSanchez27/MLOps_Proyecto_2.git #SSH
   cd MLOps_Proyecto_2

2. **Construir la imagen** definida en el Dockerfile usando Docker Compose:

   ```bash
    docker-compose build

3. **Iniciar el contenedor** en segundo plano:

   ```bash
    docker-compose up -d

4. **Verificar que el contenedor estÃ© corriendo:**
   ```bash
    docker ps

5. **Para ver los logs de un servicio:**
    ```bash
    docker-compose logs -f <nombre_servicio>

5. **Detener los Contenedores**
    Para detener los servicios sin eliminar volÃºmenes de datos:
     ```bash
    docker-compose down
      ```
    Para eliminar volÃºmenes y datos persistentes:
    ```bash
    docker-compose down -v
   ```

  DeberÃ­a ver un contenedor llamado desarrollo_container (o el que hayas definido en docker-compose.yml) en ejecuciÃ³n.

## ğŸš€ Acceso a los Servicios si se corren localmente en la maquina

---
  1. Airflow UI: http://localhost:8080
  2. MLflow UI: http://localhost:8084
  3. MinIO Console: http://localhost:8083
  4. FastAPI Inference: http://localhost:8085/docs
  5. Streamlit App: http://localhost:8086 
---

## ğŸ—ï¸ Imagenes del despliegue

![alt text](imagenes/airflow.png)

OrquestaciÃ³n en Airflow, muestra la estructura de los DAGs y la interconexiÃ³n entre tareas. Representa cÃ³mo los datos fluyen a travÃ©s de diferentes nodos y cÃ³mo se ejecutan en paralelo o en secuencia, asegurando una ejecuciÃ³n eficiente de los flujos de trabajo, para este caso un para carga de datos y otro para entrenamiento.

![imagenes\minio.png](imagenes/minio.png)

representaciÃ³n visual de los experimentos gestionados con MLflow. AquÃ­ se documentan los diferentes modelos de machine learning entrenados, junto con sus mÃ©tricas de evaluaciÃ³n y parÃ¡metros de configuraciÃ³n. Este seguimiento permite comparar modelos y seleccionar la mejor versiÃ³n para producciÃ³n.

Asi mismo se muestra una vista del almacenamiento en MinIO, donde se gestionan los artefactos generados por los procesos de machine learning. Este sistema actÃºa como un repositorio central para guardar modelos, datos transformados y otros elementos esenciales para la reproducibilidad del proyecto.

![imagenes\fastApi.png](imagenes/fastApi.png)

FastAPI se utiliza en la carpeta inference para proporcionar un servicio de inferencia de modelos de machine learning a travÃ©s de una API RESTful. Esta API permite recibir solicitudes en formato JSON con las caracterÃ­sticas necesarias para la predicciÃ³n y devuelve los resultados de manera eficiente. La documentaciÃ³n interactiva generada automÃ¡ticamente por FastAPI facilita la prueba y comprensiÃ³n de los endpoints disponibles, permitiendo integrar el servicio con otras aplicaciones dentro del ecosistema del proyecto.

![imagenes\streamlit.png](imagenes/streamlit.png)

esta ultima imagen presenta una interfaz en Streamlit que permite visualizar los resultados de los modelos y su impacto en la toma de decisiones. Se incluyen campos para el usuario que facilitan la insercion de los datos a predecir. 


## ğŸš€ Reto

Uno de los principales retos de este proyecto ha sido la correcta configuraciÃ³n de los endpoints y las conexiones entre servicios distribuidos. Dado que cada aplicaciÃ³n (Airflow, MLflow, MinIO, FastAPI, Streamlit) se ejecuta en contenedores independientes, ha sido importante establecer rutas y credenciales adecuadas para permitir la comunicaciÃ³n fluida entre ellos. Por ejemplo, el servicio de inferencia debe acceder a modelos almacenados en MinIO utilizando variables de entorno compatibles con MLflow, mientras que Streamlit consume estos endpoints para mostrar resultados en tiempo real. Esta interconexiÃ³n requiere una sincronizaciÃ³n precisa de los puertos, rutas internas en Docker y autenticaciones, lo cual representa un desafÃ­o clave al diseÃ±ar sistemas orquestados y modulares.